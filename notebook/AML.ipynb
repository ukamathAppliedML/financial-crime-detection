{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Crime Detection - Complete Demo\n",
    "\n",
    "This notebook demonstrates the complete workflow for financial crime detection using our generic framework.\n",
    "\n",
    "**Workflow Overview:**\n",
    "1. **Data Loading & Exploration** - Load and analyze the dataset\n",
    "2. **Data Preparation** - Split data into train/val/test sets\n",
    "3. **Model Training** - Train the financial crime detection model\n",
    "4. **Model Evaluation** - Evaluate performance with metrics and visualizations\n",
    "5. **Prediction Examples** - Test the model on new examples\n",
    "6. **Analysis & Insights** - Analyze results and model behavior\n",
    "\n",
    "**Current Focus:** Anti-Money Laundering (AML) Detection  \n",
    "**Framework:** Generic and extensible for other financial crime types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Our financial crime detection package\n",
    "from src import (\n",
    "    load_fincrime_dataset,\n",
    "    prepare_data_splits,\n",
    "    print_dataset_summary,\n",
    "    analyze_dataset,\n",
    "    plot_dataset_overview,\n",
    "    FinCrimeModel,\n",
    "    FinCrimePredictor,\n",
    "    FinCrimeEvaluator,\n",
    "    TEST_EXAMPLES\n",
    ")\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üìä Ready to start financial crime detection demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration\n",
    "\n",
    "Let's load and explore our financial crime dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(\"üìÅ Loading financial crime dataset...\")\n",
    "\n",
    "# Try to load the actual dataset\n",
    "try:\n",
    "    df = load_fincrime_dataset('data/AntiMoneyLaundering-v4.csv')\n",
    "    data_source = \"AntiMoneyLaundering-v4.csv\"\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load dataset: {e}\")\n",
    "    print(\"üîß Creating sample dataset for demonstration...\")\n",
    "    \n",
    "    # Create sample AML dataset\n",
    "    sample_data = {\n",
    "        'conversation': [\n",
    "            \"Standard transaction processing for client account with proper documentation\",\n",
    "            \"Keep transfers under 9k to avoid reporting requirements and paperwork\",\n",
    "            \"Route through offshore entities in Cayman Islands for privacy reasons\",\n",
    "            \"Regular business transaction with all compliance documentation provided\",\n",
    "            \"Break this large deposit into smaller amounts to avoid detection\",\n",
    "            \"Client provided all necessary compliance documentation and KYC materials\",\n",
    "            \"Use multiple accounts to structure the payments below reporting thresholds\",\n",
    "            \"Standard wire transfer with proper authorization and documentation\",\n",
    "            \"Layer the transactions through multiple jurisdictions to obscure origin\",\n",
    "            \"Normal business relationship with transparent ownership structure\",\n",
    "            \"CTR filing was missed for this large cash deposit transaction\",\n",
    "            \"All regulatory requirements met for this international wire transfer\",\n",
    "            \"Shell company arrangement to hide the true beneficial ownership\",\n",
    "            \"Legitimate business operations with proper corporate governance\",\n",
    "            \"Smurfing operation using multiple individuals for small deposits\",\n",
    "            \"Routine transaction monitoring shows normal business patterns\",\n",
    "            \"Third party intermediary to avoid direct involvement in transaction\",\n",
    "            \"Standard compliance procedures followed for this client onboarding\",\n",
    "            \"Tax avoidance scheme using offshore structures illegally\",\n",
    "            \"Investment portfolio management with proper fiduciary oversight\"\n",
    "        ] * 35,  # Multiply to get ~700 samples\n",
    "        'label': [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 35,\n",
    "        'category': [\n",
    "            'Normal Business', 'Amount Threshold', 'Offshore Accounts', 'Normal Business',\n",
    "            'Structuring', 'Normal Business', 'Structuring', 'Normal Business',\n",
    "            'Layering', 'Normal Business', 'CTR Issues', 'Normal Business',\n",
    "            'Shell Company', 'Normal Business', 'Smurfing', 'Normal Business',\n",
    "            'Third Party Transfer', 'Normal Business', 'Tax Avoidance', 'Normal Business'\n",
    "        ] * 35\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    data_source = \"Sample AML Dataset (Demo)\"\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {data_source}\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display first few examples\n",
    "print(\"\\nüîç Sample data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive dataset analysis\n",
    "print(\"üìà Dataset Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use our utility function for detailed analysis\n",
    "print_dataset_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of the dataset\n",
    "print(\"üìä Dataset Visualizations:\")\n",
    "plot_dataset_overview(df, figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Split the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data splits\n",
    "print(\"üîÑ Preparing data splits...\")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_splits(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    val_size=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data splits prepared:\")\n",
    "print(f\"   üìö Training set: {len(X_train)} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"   üîç Validation set: {len(X_val)} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"   üß™ Test set: {len(X_test)} samples ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Check label distribution in each split\n",
    "print(f\"\\nüìä Label distribution:\")\n",
    "print(f\"   Training - Normal: {y_train.count(0)}, Suspicious: {y_train.count(1)}\")\n",
    "print(f\"   Validation - Normal: {y_val.count(0)}, Suspicious: {y_val.count(1)}\")\n",
    "print(f\"   Test - Normal: {y_test.count(0)}, Suspicious: {y_test.count(1)}\")\n",
    "\n",
    "# Show some training examples\n",
    "print(f\"\\nüîç Training examples:\")\n",
    "for i in range(3):\n",
    "    label_name = \"Normal\" if y_train[i] == 0 else \"Suspicious\"\n",
    "    print(f\"   {i+1}. [{label_name}] {X_train[i][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Train the financial crime detection model using our FinCrimeModel wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "print(\"ü§ñ Initializing Financial Crime Detection Model...\")\n",
    "\n",
    "model = FinCrimeModel(model_name=\"xlm-roberta-base\")\n",
    "print(\"‚úÖ Model initialized successfully!\")\n",
    "\n",
    "# Show model info\n",
    "print(f\"\\nüìã Model Configuration:\")\n",
    "print(f\"   üèóÔ∏è Base model: xlm-roberta-base\")\n",
    "print(f\"   üéØ Task: Binary classification (Normal vs Suspicious)\")\n",
    "print(f\"   üíæ Labels: 0=Normal, 1=Suspicious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "print(\"‚öôÔ∏è Training Configuration:\")\n",
    "print(\"   For demo purposes, we'll use reduced training parameters.\")\n",
    "print(\"   For production, increase epochs and batch sizes.\")\n",
    "\n",
    "# Option 1: Quick training (uncomment for fast demo)\n",
    "training_config = {\n",
    "    'epochs': 1,\n",
    "    'batch_size': 8,\n",
    "    'description': 'Quick training for demonstration'\n",
    "}\n",
    "\n",
    "# Option 2: Full training (uncomment for production)\n",
    "# training_config = {\n",
    "#     'epochs': 3,\n",
    "#     'batch_size': 16,\n",
    "#     'description': 'Full training for production'\n",
    "# }\n",
    "\n",
    "print(f\"\\nüöÄ {training_config['description']}:\")\n",
    "print(f\"   üìä Epochs: {training_config['epochs']}\")\n",
    "print(f\"   üì¶ Batch size: {training_config['batch_size']}\")\n",
    "print(f\"   ‚è±Ô∏è Expected time: {'5-10 minutes' if training_config['epochs'] == 1 else '20-30 minutes'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üéØ Starting model training...\")\n",
    "print(\"\" * 50)\n",
    "\n",
    "# Train the model\n",
    "training_results, test_dataset = model.train(\n",
    "    X_train, y_train, \n",
    "    X_val, y_val, \n",
    "    X_test, y_test,\n",
    "    output_dir='./notebook_trained_model'\n",
    ")\n",
    "\n",
    "print(\"\" * 50)\n",
    "print(\"üéâ Training completed!\")\n",
    "print(f\"‚è±Ô∏è Training time: {training_results.metrics.get('train_runtime', 'N/A'):.2f} seconds\")\n",
    "print(f\"üìâ Final training loss: {training_results.metrics.get('train_loss', 'N/A'):.4f}\")\n",
    "print(f\"üìä Training samples processed: {training_results.metrics.get('train_samples', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "print(\"üíæ Saving trained model...\")\n",
    "model.save_model('./notebook_trained_model')\n",
    "print(\"‚úÖ Model saved successfully!\")\n",
    "print(\"üìÅ Model location: ./notebook_trained_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Evaluate the trained model's performance using our evaluation wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for evaluation\n",
    "print(\"üîç Loading trained model for evaluation...\")\n",
    "\n",
    "predictor = FinCrimePredictor('./notebook_trained_model')\n",
    "evaluator = FinCrimeEvaluator(predictor)\n",
    "\n",
    "print(\"‚úÖ Model loaded for evaluation!\")\n",
    "print(f\"üìã Model info: {predictor.get_model_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model evaluation\n",
    "print(\"üìä Model Performance Evaluation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use our evaluator for comprehensive analysis\n",
    "evaluator.print_evaluation_summary(X_test, y_test)\n",
    "\n",
    "# Get detailed metrics\n",
    "metrics = evaluator.evaluate(X_test, y_test)\n",
    "print(f\"\\nüìà Key Performance Indicators:\")\n",
    "print(f\"   üéØ Overall Accuracy: {metrics['accuracy']:.1%}\")\n",
    "print(f\"   üîç Suspicious Detection Precision: {metrics['precision_suspicious']:.1%}\")\n",
    "print(f\"   üì° Suspicious Detection Recall: {metrics['recall_suspicious']:.1%}\")\n",
    "print(f\"   ‚öñÔ∏è F1-Score: {metrics['f1_suspicious']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualizations\n",
    "print(\"üìä Performance Visualizations:\")\n",
    "\n",
    "# Confusion matrix\n",
    "evaluator.plot_confusion_matrix(X_test, y_test, figsize=(8, 6))\n",
    "\n",
    "# Performance metrics\n",
    "evaluator.plot_performance_metrics(X_test, y_test, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified examples\n",
    "print(\"üîç Misclassification Analysis:\")\n",
    "\n",
    "misclassified = evaluator.find_misclassified_examples(X_test, y_test)\n",
    "\n",
    "print(f\"\\nüìä Misclassification Summary:\")\n",
    "print(f\"   ‚ùå False Positives (Normal‚ÜíSuspicious): {len(misclassified['false_positives'])}\")\n",
    "print(f\"   ‚ùå False Negatives (Suspicious‚ÜíNormal): {len(misclassified['false_negatives'])}\")\n",
    "\n",
    "# Show some misclassified examples\n",
    "if misclassified['false_positives']:\n",
    "    print(f\"\\nüîç Sample False Positives:\")\n",
    "    for i, fp in enumerate(misclassified['false_positives'][:3]):\n",
    "        print(f\"   {i+1}. {fp['text'][:100]}...\")\n",
    "        print(f\"      Confidence: {fp['confidence']:.3f}\")\n",
    "\n",
    "if misclassified['false_negatives']:\n",
    "    print(f\"\\nüîç Sample False Negatives:\")\n",
    "    for i, fn in enumerate(misclassified['false_negatives'][:3]):\n",
    "        print(f\"   {i+1}. {fn['text'][:100]}...\")\n",
    "        print(f\"      Confidence: {fn['confidence']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction Examples\n",
    "\n",
    "Test the model on new examples to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on predefined examples\n",
    "print(\"üß™ Testing on Predefined Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, example in enumerate(TEST_EXAMPLES, 1):\n",
    "    result = predictor.predict(example['text'])\n",
    "    expected = example['expected']\n",
    "    actual = result['label']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    # Check if prediction matches expectation\n",
    "    status = \"‚úÖ\" if actual == expected else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status} Example {i}:\")\n",
    "    print(f\"   üìù Text: {example['text'][:80]}...\")\n",
    "    print(f\"   üéØ Expected: {expected}\")\n",
    "    print(f\"   ü§ñ Predicted: {actual} (Confidence: {confidence:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on custom examples\n",
    "print(\"üéØ Testing on Additional Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Add your own test examples here\n",
    "custom_examples = [\n",
    "    \"The client wants to structure payments to avoid CTR filing requirements\",\n",
    "    \"Standard wire transfer with proper KYC documentation completed\",\n",
    "    \"Using multiple bank accounts to break up large transactions\",\n",
    "    \"Legitimate business transaction with board approval\",\n",
    "    \"Offshore shell company setup to hide beneficial ownership\",\n",
    "    \"Regular monthly payment to supplier with invoice documentation\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(custom_examples, 1):\n",
    "    result = predictor.predict(text)\n",
    "    detailed_result = predictor.predict_with_probabilities(text)\n",
    "    \n",
    "    print(f\"\\nüìù Example {i}:\")\n",
    "    print(f\"   Text: {text}\")\n",
    "    print(f\"   ü§ñ Prediction: {result['label']} (Confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"   üìä Probabilities: Normal={detailed_result['probabilities']['Normal']:.3f}, Suspicious={detailed_result['probabilities']['Suspicious']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_text(text):\n",
    "    \"\"\"Interactive prediction function for notebook use\"\"\"\n",
    "    result = predictor.predict_with_probabilities(text)\n",
    "    \n",
    "    print(f\"üìù Input: {text}\")\n",
    "    print(f\"ü§ñ Prediction: {result['label']}\")\n",
    "    print(f\"üìä Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"üìà Probabilities:\")\n",
    "    print(f\"   Normal: {result['probabilities']['Normal']:.3f}\")\n",
    "    print(f\"   Suspicious: {result['probabilities']['Suspicious']:.3f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "print(\"üîß Interactive Prediction Function Ready!\")\n",
    "print(\"\\nExample usage:\")\n",
    "print('predict_text(\"Your text here\")')\n",
    "\n",
    "# Test the function\n",
    "print(\"\\nüß™ Testing the function:\")\n",
    "predict_text(\"Keep the deposit amounts under the reporting threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis & Insights\n",
    "\n",
    "Analyze the model's behavior and provide insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence score analysis\n",
    "print(\"üìä Confidence Score Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get predictions for all test examples\n",
    "all_predictions = []\n",
    "for text, true_label in zip(X_test, y_test):\n",
    "    result = predictor.predict(text)\n",
    "    all_predictions.append({\n",
    "        'text': text,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': result['class_id'],\n",
    "        'confidence': result['confidence'],\n",
    "        'correct': true_label == result['class_id']\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "results_df = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Confidence statistics\n",
    "print(f\"üìà Overall Confidence Statistics:\")\n",
    "print(f\"   Mean confidence: {results_df['confidence'].mean():.3f}\")\n",
    "print(f\"   Median confidence: {results_df['confidence'].median():.3f}\")\n",
    "print(f\"   Min confidence: {results_df['confidence'].min():.3f}\")\n",
    "print(f\"   Max confidence: {results_df['confidence'].max():.3f}\")\n",
    "\n",
    "# Confidence by correctness\n",
    "print(f\"\\nüéØ Confidence by Prediction Correctness:\")\n",
    "correct_conf = results_df[results_df['correct']]['confidence'].mean()\n",
    "incorrect_conf = results_df[~results_df['correct']]['confidence'].mean()\n",
    "print(f\"   Correct predictions: {correct_conf:.3f}\")\n",
    "print(f\"   Incorrect predictions: {incorrect_conf:.3f}\")\n",
    "\n",
    "# Plot confidence distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(results_df[results_df['correct']]['confidence'], alpha=0.7, label='Correct', bins=20)\n",
    "plt.hist(results_df[~results_df['correct']]['confidence'], alpha=0.7, label='Incorrect', bins=20)\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Distribution by Correctness')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(results_df['confidence'], results_df['correct'], alpha=0.6)\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Correct (1) vs Incorrect (0)')\n",
    "plt.title('Confidence vs Correctness')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model insights and recommendations\n",
    "print(\"üîç Model Insights & Recommendations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate key metrics\n",
    "accuracy = metrics['accuracy']\n",
    "precision = metrics['precision_suspicious']\n",
    "recall = metrics['recall_suspicious']\n",
    "f1 = metrics['f1_suspicious']\n",
    "\n",
    "print(f\"\\nüìä Performance Assessment:\")\n",
    "if accuracy >= 0.9:\n",
    "    print(f\"   ‚úÖ Excellent accuracy ({accuracy:.1%}) - Model performs very well\")\n",
    "elif accuracy >= 0.8:\n",
    "    print(f\"   ‚úÖ Good accuracy ({accuracy:.1%}) - Model performs well\")\n",
    "elif accuracy >= 0.7:\n",
    "    print(f\"   ‚ö†Ô∏è Moderate accuracy ({accuracy:.1%}) - Room for improvement\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Low accuracy ({accuracy:.1%}) - Needs significant improvement\")\n",
    "\n",
    "print(f\"\\nüéØ Suspicious Activity Detection:\")\n",
    "if precision >= 0.9 and recall >= 0.9:\n",
    "    print(f\"   ‚úÖ Excellent detection capability (P:{precision:.1%}, R:{recall:.1%})\")\n",
    "elif precision >= 0.8 and recall >= 0.8:\n",
    "    print(f\"   ‚úÖ Good detection capability (P:{precision:.1%}, R:{recall:.1%})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Detection needs improvement (P:{precision:.1%}, R:{recall:.1%})\")\n",
    "\n",
    "print(f\"\\nüîß Recommendations:\")\n",
    "if len(misclassified['false_positives']) > len(misclassified['false_negatives']):\n",
    "    print(f\"   üìà Consider increasing precision (too many false alarms)\")\n",
    "elif len(misclassified['false_negatives']) > len(misclassified['false_positives']):\n",
    "    print(f\"   üìà Consider increasing recall (missing suspicious cases)\")\n",
    "else:\n",
    "    print(f\"   ‚öñÔ∏è Good balance between precision and recall\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Collect more training data for better performance\")\n",
    "print(f\"   2. Fine-tune model parameters for your specific use case\")\n",
    "print(f\"   3. Consider ensemble methods for improved accuracy\")\n",
    "print(f\"   4. Implement continuous learning with new data\")\n",
    "print(f\"   5. Add domain-specific features if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "print(\"üìã Detailed Classification Report:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "classification_report = evaluator.generate_classification_report(X_test, y_test)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary & Conclusion\n",
    "\n",
    "Summary of the complete financial crime detection workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù FINANCIAL CRIME DETECTION - DEMO SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"   üìÅ Source: {data_source}\")\n",
    "print(f\"   üìè Total samples: {len(df)}\")\n",
    "print(f\"   üè∑Ô∏è Normal samples: {len(df[df['label'] == 0])}\")\n",
    "print(f\"   üö® Suspicious samples: {len(df[df['label'] == 1])}\")\n",
    "\n",
    "print(f\"\\nü§ñ Model Information:\")\n",
    "print(f\"   üèóÔ∏è Architecture: XLM-RoBERTa Base\")\n",
    "print(f\"   üéØ Task: Binary Classification\")\n",
    "print(f\"   üìä Training samples: {len(X_train)}\")\n",
    "print(f\"   üîç Validation samples: {len(X_val)}\")\n",
    "print(f\"   üß™ Test samples: {len(X_test)}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Results:\")\n",
    "print(f\"   üéØ Accuracy: {metrics['accuracy']:.1%}\")\n",
    "print(f\"   üîç Precision: {metrics['precision_suspicious']:.1%}\")\n",
    "print(f\"   üì° Recall: {metrics['recall_suspicious']:.1%}\")\n",
    "print(f\"   ‚öñÔ∏è F1-Score: {metrics['f1_suspicious']:.1%}\")\n",
    "print(f\"   üìä True Positives: {metrics['true_positives']}\")\n",
    "print(f\"   üìä True Negatives: {metrics['true_negatives']}\")\n",
    "print(f\"   ‚ùå False Positives: {metrics['false_positives']}\")\n",
    "print(f\"   ‚ùå False Negatives: {metrics['false_negatives']}\")\n",
    "\n",
    "print(f\"\\nüîß Technical Implementation:\")\n",
    "print(f\"   üì¶ Package: Generic Financial Crime Detection Framework\")\n",
    "print(f\"   üêç Components: FinCrimeModel, FinCrimePredictor, FinCrimeEvaluator\")\n",
    "print(f\"   üîÑ Workflow: Load ‚Üí Prepare ‚Üí Train ‚Üí Evaluate ‚Üí Predict\")\n",
    "print(f\"   üìÅ Model saved: ./notebook_trained_model\")\n",
    "\n",
    "\n",
    "print(f\"\\nüéâ Demo completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
